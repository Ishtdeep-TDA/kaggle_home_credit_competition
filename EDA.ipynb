{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_applprev_1_0.csv', 'train_applprev_1_1.csv', 'train_applprev_2.csv', 'train_base.csv', 'train_credit_bureau_a_1_0.csv', 'train_credit_bureau_a_1_1.csv', 'train_credit_bureau_a_1_2.csv', 'train_credit_bureau_a_1_3.csv', 'train_credit_bureau_a_2_0.csv', 'train_credit_bureau_a_2_1.csv', 'train_credit_bureau_a_2_10.csv', 'train_credit_bureau_a_2_2.csv', 'train_credit_bureau_a_2_3.csv', 'train_credit_bureau_a_2_4.csv', 'train_credit_bureau_a_2_5.csv', 'train_credit_bureau_a_2_6.csv', 'train_credit_bureau_a_2_7.csv', 'train_credit_bureau_a_2_8.csv', 'train_credit_bureau_a_2_9.csv', 'train_credit_bureau_b_1.csv', 'train_credit_bureau_b_2.csv', 'train_debitcard_1.csv', 'train_deposit_1.csv', 'train_other_1.csv', 'train_person_1.csv', 'train_person_2.csv', 'train_static_0_0.csv', 'train_static_0_1.csv', 'train_static_cb_0.csv', 'train_tax_registry_a_1.csv', 'train_tax_registry_b_1.csv', 'train_tax_registry_c_1.csv']\n",
      "['train_applprev_1_0.csv', 'train_applprev_1_1.csv', 'train_applprev_2.csv', 'train_base.csv', 'train_credit_bureau_a_1_0.csv', 'train_credit_bureau_a_1_1.csv', 'train_credit_bureau_a_1_2.csv', 'train_credit_bureau_a_1_3.csv', 'train_credit_bureau_a_2_0.csv', 'train_credit_bureau_a_2_1.csv', 'train_credit_bureau_a_2_10.csv', 'train_credit_bureau_a_2_2.csv', 'train_credit_bureau_a_2_3.csv', 'train_credit_bureau_a_2_4.csv', 'train_credit_bureau_a_2_5.csv', 'train_credit_bureau_a_2_6.csv', 'train_credit_bureau_a_2_7.csv', 'train_credit_bureau_a_2_8.csv', 'train_credit_bureau_a_2_9.csv', 'train_credit_bureau_b_1.csv', 'train_credit_bureau_b_2.csv', 'train_debitcard_1.csv', 'train_deposit_1.csv', 'train_other_1.csv', 'train_person_1.csv', 'train_person_2.csv', 'train_static_0_0.csv', 'train_static_0_1.csv', 'train_static_cb_0.csv', 'train_tax_registry_a_1.csv', 'train_tax_registry_b_1.csv', 'train_tax_registry_c_1.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\ishtd\\AppData\\Local\\Temp\\ipykernel_22628\\1888811822.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  train_path = \"D:\\Datasets\\kaggle_home_credit\\csv_files/train/\"\n",
      "C:\\Users\\ishtd\\AppData\\Local\\Temp\\ipykernel_22628\\1888811822.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  optimized_df_path = \"D:\\Datasets\\kaggle_home_credit\\csv_files/optimized_df/\"\n"
     ]
    }
   ],
   "source": [
    "train_path = \"D:\\Datasets\\kaggle_home_credit\\csv_files/train/\"\n",
    "optimized_df_path = \"D:\\Datasets\\kaggle_home_credit\\csv_files/optimized_df/\"\n",
    "train_dfs = os.listdir(train_path)\n",
    "print(train_dfs)\n",
    "# train_dfs = [train_path + i for i in train_dfs]\n",
    "print(train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Optimize the data types of a pandas DataFrame to reduce memory usage.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to optimize.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame with optimized data types.\n",
    "    \"\"\"\n",
    "    optimized_df = df.copy()\n",
    "    \n",
    "    # Optimize numeric columns\n",
    "    for col in optimized_df.select_dtypes(include=['int', 'float']).columns:\n",
    "        col_min = optimized_df[col].min()\n",
    "        col_max = optimized_df[col].max()\n",
    "        \n",
    "        if pd.api.types.is_integer_dtype(optimized_df[col]):\n",
    "            if col_min >= np.iinfo(np.int8).min and col_max <= np.iinfo(np.int8).max:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.int8)\n",
    "            elif col_min >= np.iinfo(np.int16).min and col_max <= np.iinfo(np.int16).max:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.int16)\n",
    "            elif col_min >= np.iinfo(np.int32).min and col_max <= np.iinfo(np.int32).max:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.int32)\n",
    "            else:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.int64)\n",
    "        else:\n",
    "            if col_min >= np.finfo(np.float16).min and col_max <= np.finfo(np.float16).max:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.float16)\n",
    "            elif col_min >= np.finfo(np.float32).min and col_max <= np.finfo(np.float32).max:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.float32)\n",
    "            else:\n",
    "                optimized_df[col] = optimized_df[col].astype(np.float64)\n",
    "    \n",
    "    # Optimize object columns\n",
    "    for col in optimized_df.select_dtypes(include=['object']).columns:\n",
    "        num_unique_values = len(optimized_df[col].unique())\n",
    "        num_total_values = len(optimized_df[col])\n",
    "        if num_unique_values / num_total_values < 0.5:\n",
    "            optimized_df[col] = optimized_df[col].astype('category')\n",
    "    \n",
    "    return optimized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'applprev', 'debitcard', 'person', 'static', 'deposit', 'other', 'credit', 'tax', 'base.csv'}\n"
     ]
    }
   ],
   "source": [
    "data_categories = set([file_name.split(\"_\")[1] for file_name in train_dfs])\n",
    "print(data_categories)\n",
    "data = defaultdict(list)\n",
    "for file_name in train_dfs:\n",
    "    name_split = file_name.split(\"_\")\n",
    "    data[name_split[1]].append(train_path + file_name)\n",
    "\n",
    "def optimize_dfs(data_dict,category):\n",
    "    '''\n",
    "    Loads data according to the category in a df and stores it in the dictionary\n",
    "\n",
    "    '''\n",
    "    for index,path in enumerate(data_dict[category]): \n",
    "        print(path)   \n",
    "        temp_df = pd.read_csv(path)\n",
    "        optimized_df = optimize_dataframe(temp_df)\n",
    "        optimized_df.to_pickle(f'{optimized_df_path}/{category}_{index}.pkl')\n",
    "        data_dict[index] = f'{optimized_df_path}/{category}_{index}.pkl'\n",
    "\n",
    "def load_data(data_dict,category):\n",
    "    '''\n",
    "    Loads data according to the category in a df and stores it in the dictionary\n",
    "\n",
    "    '''\n",
    "    df_list = []\n",
    "    for path in data_dict[category]:    \n",
    "        temp_df = pd.read_pickle(path)\n",
    "        df_list.append(temp_df)\n",
    "    data_dict[category] = df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_1_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishtd\\AppData\\Local\\Temp\\ipykernel_22628\\159905399.py:15: DtypeWarning: Columns (11,12,14,30,44,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_1_1.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_1_2.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_1_3.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_0.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_1.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_10.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_2.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_3.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_4.csv\n",
      "D:\\Datasets\\kaggle_home_credit\\csv_files/train/train_credit_bureau_a_2_5.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptimize_dfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcredit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m, in \u001b[0;36moptimize_dfs\u001b[1;34m(data_dict, category)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_dict[category]): \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(path)   \n\u001b[1;32m---> 15\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     optimized_df \u001b[38;5;241m=\u001b[39m optimize_dataframe(temp_df)\n\u001b[0;32m     17\u001b[0m     optimized_df\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimized_df_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2215\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2214\u001b[0m         values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n\u001b[1;32m-> 2215\u001b[0m     blk \u001b[38;5;241m=\u001b[39m block_type(values, placement\u001b[38;5;241m=\u001b[39m\u001b[43mBlockPlacement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m)\u001b[49m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   2216\u001b[0m     nbs\u001b[38;5;241m.\u001b[39mappend(blk)\n\u001b[0;32m   2218\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(dtype):\n",
      "File \u001b[1;32minternals.pyx:67\u001b[0m, in \u001b[0;36mpandas._libs.internals.BlockPlacement.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\numpy\\core\\_asarray.py:27\u001b[0m, in \u001b[0;36mrequire\u001b[1;34m(a, dtype, requirements, like)\u001b[0m\n\u001b[0;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequire\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     17\u001b[0m POSSIBLE_FLAGS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CONTIGUOUS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONTIGUOUS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF_CONTIGUOUS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORTRAN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENSUREARRAY\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m }\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;129m@set_array_function_like_doc\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequire\u001b[39m(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, requirements\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, like\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Return an ndarray of the provided type that satisfies requirements.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize_dfs(data,\"credit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishtd\\AppData\\Local\\Temp\\ipykernel_22628\\463257710.py:15: DtypeWarning: Columns (11,12,14,30,44,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(path)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m base_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(train_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_base.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# load_data(data,'applprev')\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcredit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_dict, category)\u001b[0m\n\u001b[0;32m     13\u001b[0m df_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m data_dict[category]:    \n\u001b[1;32m---> 15\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(temp_df)\n\u001b[0;32m     17\u001b[0m data_dict[category] \u001b[38;5;241m=\u001b[39m df_list\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2287\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2294\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2296\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32mc:\\Users\\ishtd\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# base_df contains case id and basic stuff\n",
    "base_df = pd.read_csv(train_path + \"train_base.csv\")\n",
    "# load_data(data,'applprev')\n",
    "load_data(data,'credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>date_decision</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id date_decision   MONTH  WEEK_NUM  target\n",
       "0        0    2019-01-03  201901         0       0\n",
       "1        1    2019-01-03  201901         0       0\n",
       "2        2    2019-01-04  201901         0       0\n",
       "3        3    2019-01-03  201901         0       0\n",
       "4        4    2019-01-04  201901         0       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# important stats on base df\n",
    "# total cases = 1526659\n",
    "#\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3275770, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tax'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns and their null value counts\n",
      "case_id\n",
      "null percentage  0.0\n",
      "number of unique values  335275\n",
      "[388 405 409 410 411 414 415 416 417 418]\n",
      "\n",
      "annualeffectiverate_199L\n",
      "annualeffectiverate_199L has too many nulls\n",
      "\n",
      "annualeffectiverate_63L\n",
      "annualeffectiverate_63L has too many nulls\n",
      "\n",
      "classificationofcontr_13M\n",
      "null percentage  0.0\n",
      "number of unique values  11\n",
      "['ea6782cc' '4408ff0f' 'a55475b1' '01f63ac8' '00135d9c' 'be7b251d'\n",
      " '1cf4e481' '2c070815' '0d95a828' '87bdbcba']\n",
      "\n",
      "classificationofcontr_400M\n",
      "null percentage  0.0\n",
      "number of unique values  269\n",
      "['a55475b1' '42a42e75' '9158339f' 'ec922b98' 'ea6782cc' '01f63ac8'\n",
      " '00135d9c' '4d2b9cd0' 'e6e56e83' '601cfe5f']\n",
      "\n",
      "contractst_545M\n",
      "null percentage  0.0\n",
      "number of unique values  43\n",
      "['7241344e' 'a55475b1' '0dc85f9d' '8f3a197f' 'a52d5641' 'b919198c'\n",
      " '3d18d6ef' '885ce291' '7640edc3' 'e2e7d341']\n",
      "\n",
      "contractst_964M\n",
      "null percentage  0.0\n",
      "number of unique values  156\n",
      "['a55475b1' '7241344e' '4476359f' '9c5b185b' '88c858bd' 'b83056f9'\n",
      " '8f3a197f' 'fec76166' 'ec24545f' 'd7416962']\n",
      "\n",
      "contractsum_5085717L\n",
      "contractsum_5085717L has too many nulls\n",
      "\n",
      "credlmt_230A\n",
      "credlmt_230A has too many nulls\n",
      "\n",
      "credlmt_935A\n",
      "credlmt_935A has too many nulls\n",
      "\n",
      "dateofcredend_289D\n",
      "dateofcredend_289D has too many nulls\n",
      "\n",
      "dateofcredend_353D\n",
      "dateofcredend_353D has too many nulls\n",
      "\n",
      "dateofcredstart_181D\n",
      "dateofcredstart_181D has too many nulls\n",
      "\n",
      "dateofcredstart_739D\n",
      "dateofcredstart_739D has too many nulls\n",
      "\n",
      "dateofrealrepmt_138D\n",
      "dateofrealrepmt_138D has too many nulls\n",
      "\n",
      "debtoutstand_525A\n",
      "debtoutstand_525A has too many nulls\n",
      "\n",
      "debtoverdue_47A\n",
      "debtoverdue_47A has too many nulls\n",
      "\n",
      "description_351M\n",
      "null percentage  0.0\n",
      "number of unique values  12\n",
      "['a55475b1' 'f8e51f8d' '53179c19' '8a7423d5' '18e98e64' '1d89fa48'\n",
      " '95decc86' '6da7c7ed' '0349102c' '0cb4d552']\n",
      "\n",
      "dpdmax_139P\n",
      "dpdmax_139P has too many nulls\n",
      "\n",
      "dpdmax_757P\n",
      "dpdmax_757P has too many nulls\n",
      "\n",
      "dpdmaxdatemonth_442T\n",
      "dpdmaxdatemonth_442T has too many nulls\n",
      "\n",
      "dpdmaxdatemonth_89T\n",
      "dpdmaxdatemonth_89T has too many nulls\n",
      "\n",
      "dpdmaxdateyear_596T\n",
      "dpdmaxdateyear_596T has too many nulls\n",
      "\n",
      "dpdmaxdateyear_896T\n",
      "dpdmaxdateyear_896T has too many nulls\n",
      "\n",
      "financialinstitution_382M\n",
      "null percentage  0.0\n",
      "number of unique values  211\n",
      "['a55475b1' 'b619fa46' 'P40_52_135' '9a93e20f' 'P133_127_114' 'P20_84_65'\n",
      " '9325d851' 'P204_66_73' 'P150_136_157' 'P51_123_23']\n",
      "\n",
      "financialinstitution_591M\n",
      "null percentage  0.0\n",
      "number of unique values  137\n",
      "['P204_66_73' '55b002a9' 'a55475b1' 'P133_127_114' 'P150_136_157'\n",
      " '50babcd4' 'd6a7d943' '84d62c22' 'd35b8336' 'P51_123_23']\n",
      "\n",
      "instlamount_768A\n",
      "instlamount_768A has too many nulls\n",
      "\n",
      "instlamount_852A\n",
      "instlamount_852A has too many nulls\n",
      "\n",
      "interestrate_508L\n",
      "interestrate_508L has too many nulls\n",
      "\n",
      "lastupdate_1112D\n",
      "lastupdate_1112D has too many nulls\n",
      "\n",
      "lastupdate_388D\n",
      "lastupdate_388D has too many nulls\n",
      "\n",
      "monthlyinstlamount_332A\n",
      "monthlyinstlamount_332A has too many nulls\n",
      "\n",
      "monthlyinstlamount_674A\n",
      "monthlyinstlamount_674A has too many nulls\n",
      "\n",
      "nominalrate_281L\n",
      "nominalrate_281L has too many nulls\n",
      "\n",
      "nominalrate_498L\n",
      "nominalrate_498L has too many nulls\n",
      "\n",
      "num_group1\n",
      "null percentage  0.0\n",
      "number of unique values  281\n",
      "[1 0 2 3 4 5 6 7 8 9]\n",
      "\n",
      "numberofcontrsvalue_258L\n",
      "numberofcontrsvalue_258L has too many nulls\n",
      "\n",
      "numberofcontrsvalue_358L\n",
      "numberofcontrsvalue_358L has too many nulls\n",
      "\n",
      "numberofinstls_229L\n",
      "numberofinstls_229L has too many nulls\n",
      "\n",
      "numberofinstls_320L\n",
      "numberofinstls_320L has too many nulls\n",
      "\n",
      "numberofoutstandinstls_520L\n",
      "numberofoutstandinstls_520L has too many nulls\n",
      "\n",
      "numberofoutstandinstls_59L\n",
      "numberofoutstandinstls_59L has too many nulls\n",
      "\n",
      "numberofoverdueinstlmax_1039L\n",
      "numberofoverdueinstlmax_1039L has too many nulls\n",
      "\n",
      "numberofoverdueinstlmax_1151L\n",
      "numberofoverdueinstlmax_1151L has too many nulls\n",
      "\n",
      "numberofoverdueinstlmaxdat_148D\n",
      "numberofoverdueinstlmaxdat_148D has too many nulls\n",
      "\n",
      "numberofoverdueinstlmaxdat_641D\n",
      "numberofoverdueinstlmaxdat_641D has too many nulls\n",
      "\n",
      "numberofoverdueinstls_725L\n",
      "numberofoverdueinstls_725L has too many nulls\n",
      "\n",
      "numberofoverdueinstls_834L\n",
      "numberofoverdueinstls_834L has too many nulls\n",
      "\n",
      "outstandingamount_354A\n",
      "outstandingamount_354A has too many nulls\n",
      "\n",
      "outstandingamount_362A\n",
      "outstandingamount_362A has too many nulls\n",
      "\n",
      "overdueamount_31A\n",
      "overdueamount_31A has too many nulls\n",
      "\n",
      "overdueamount_659A\n",
      "overdueamount_659A has too many nulls\n",
      "\n",
      "overdueamountmax2_14A\n",
      "overdueamountmax2_14A has too many nulls\n",
      "\n",
      "overdueamountmax2_398A\n",
      "overdueamountmax2_398A has too many nulls\n",
      "\n",
      "overdueamountmax2date_1002D\n",
      "overdueamountmax2date_1002D has too many nulls\n",
      "\n",
      "overdueamountmax2date_1142D\n",
      "overdueamountmax2date_1142D has too many nulls\n",
      "\n",
      "overdueamountmax_155A\n",
      "overdueamountmax_155A has too many nulls\n",
      "\n",
      "overdueamountmax_35A\n",
      "overdueamountmax_35A has too many nulls\n",
      "\n",
      "overdueamountmaxdatemonth_284T\n",
      "overdueamountmaxdatemonth_284T has too many nulls\n",
      "\n",
      "overdueamountmaxdatemonth_365T\n",
      "overdueamountmaxdatemonth_365T has too many nulls\n",
      "\n",
      "overdueamountmaxdateyear_2T\n",
      "overdueamountmaxdateyear_2T has too many nulls\n",
      "\n",
      "overdueamountmaxdateyear_994T\n",
      "overdueamountmaxdateyear_994T has too many nulls\n",
      "\n",
      "periodicityofpmts_1102L\n",
      "periodicityofpmts_1102L has too many nulls\n",
      "\n",
      "periodicityofpmts_837L\n",
      "periodicityofpmts_837L has too many nulls\n",
      "\n",
      "prolongationcount_1120L\n",
      "prolongationcount_1120L has too many nulls\n",
      "\n",
      "prolongationcount_599L\n",
      "prolongationcount_599L has too many nulls\n",
      "\n",
      "purposeofcred_426M\n",
      "null percentage  0.0\n",
      "number of unique values  12\n",
      "['60c73645' '96a8fdfe' 'a55475b1' 'e19fdece' '7a7d6960' '9e302002'\n",
      " 'P188_162_121' '28bfa260' 'e8f3b178' '44164129']\n",
      "\n",
      "purposeofcred_874M\n",
      "null percentage  0.0\n",
      "number of unique values  18\n",
      "['a55475b1' '5065c2b8' 'e19fdece' '96a8fdfe' '60c73645' 'd9ae1a0e'\n",
      " '27b6de28' '89ccf2a3' 'ee7d1eb8' '5d1b0cdd']\n",
      "\n",
      "refreshdate_3813885D\n",
      "refreshdate_3813885D has too many nulls\n",
      "\n",
      "residualamount_488A\n",
      "residualamount_488A has too many nulls\n",
      "\n",
      "residualamount_856A\n",
      "residualamount_856A has too many nulls\n",
      "\n",
      "subjectrole_182M\n",
      "null percentage  0.0\n",
      "number of unique values  7\n",
      "['a55475b1' 'ab3c25cf' 'be4fd70b' 'daf49a8a' 'P28_48_88' '15f04f45'\n",
      " '0c42a10e']\n",
      "\n",
      "subjectrole_93M\n",
      "null percentage  0.0\n",
      "number of unique values  7\n",
      "['a55475b1' 'ab3c25cf' 'daf49a8a' 'be4fd70b' '15f04f45' '0c42a10e'\n",
      " '71ddaa88']\n",
      "\n",
      "totalamount_6A\n",
      "totalamount_6A has too many nulls\n",
      "\n",
      "totalamount_996A\n",
      "totalamount_996A has too many nulls\n",
      "\n",
      "totaldebtoverduevalue_178A\n",
      "totaldebtoverduevalue_178A has too many nulls\n",
      "\n",
      "totaldebtoverduevalue_718A\n",
      "totaldebtoverduevalue_718A has too many nulls\n",
      "\n",
      "totaloutstanddebtvalue_39A\n",
      "totaloutstanddebtvalue_39A has too many nulls\n",
      "\n",
      "totaloutstanddebtvalue_668A\n",
      "totaloutstanddebtvalue_668A has too many nulls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_description(df,nulls_threshold = 0.3):\n",
    "    print(\"All columns and their null value counts\")\n",
    "    for i in df.columns:\n",
    "        nulls = df[i].isna().sum()\n",
    "        if (nulls/df.shape[0]) < nulls_threshold:\n",
    "            print(i)\n",
    "            print(\"null percentage \", nulls/df.shape[0])\n",
    "            print(\"number of unique values \", df[i].nunique())\n",
    "            print(df[i].unique()[:10])\n",
    "            print()\n",
    "        else:\n",
    "            print(i)\n",
    "            print(f\"{i} has too many nulls\")\n",
    "            print()\n",
    "    \n",
    "basic_description(data[\"credit\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Interesting things about the data\n",
    "* Appl prev\n",
    "\n",
    "    * Important columns : actualdpd_943P - days past due,credacc_credlmt_575A,credamount_590A,credtype_587L,currdebt_94A\n",
    "    district_544M,downpmt_134A,status_219L,tenor_203L\n",
    "    * Feature creation column - approvaldate_319D,credtype_587L,district_544M,dtlastpmt_581D,dtlastpmtallstes_3545839D,education_1138M,employedfrom_700D,familystate_726L,isdebitcard_527L,mainoccupationinc_437A,maxdpdtolerance_577P,outstandingdebt_522A,profession_152M,rejectreason_755M,rejectreasonclient_4145042M,revolvingaccount_394A,tenor_203L\n",
    "\n",
    "    * childnum_21L - why 20 unique values??\n",
    "\n",
    "* person\n",
    "    * Important columns : zipcode,education_927M,empl_industry_691L,gender_992L,mainoccupationinc_384A,type_25L\n",
    "\n",
    "* debitcard\n",
    "    * Important columns : \n",
    "* Tax\n",
    "    * Important columns : amount_4527230A\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering ideas \n",
    "* Feature around location (zipcode etc)\n",
    "* Feature around total debt, acc balance etc,\n",
    "* counts on number of accts, cards, \n",
    "* total of tenor \n",
    "* date from features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305137"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
